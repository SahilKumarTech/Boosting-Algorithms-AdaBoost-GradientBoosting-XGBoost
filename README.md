# Boosting-Algorithms-AdaBoost-GradientBoosting-XGBoost
Implementation and comparison of Boosting algorithms (AdaBoost, Gradient Boosting, and XGBoost) on classification and regression tasks using Scikit-learn and XGBoost.

This repository demonstrates the implementation of **Boosting Algorithms** for both **classification** and **regression** tasks using:
- [AdaBoost Regressor & Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html)
- [Gradient Boosting Regressor & Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html)
- [XGBoost Regressor & Classifier](https://xgboost.readthedocs.io/en/stable/)

The notebook compares these models in terms of performance using metrics like **Accuracy, Precision, Recall, F1-score, RÂ² Score, MSE, RMSE**, etc.

---

## ðŸ“Œ Features
- Generate synthetic datasets for both **classification** and **regression**.
- Train models using AdaBoost, Gradient Boosting, and XGBoost.
- Evaluate models with appropriate metrics.
- Perform hyperparameter tuning for optimization.

---

## ðŸ“‚ Project File
- Adaboost_Gradient_And_Xgboost.ipynb # Main Jupyter Notebook

  
